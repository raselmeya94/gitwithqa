# # src/llm_chat/logic.py
# def get_llm_response(text: str, query: str) -> str:
#     # Example dummy logic â€” replace with actual API/model call
#     return f"Received query: '{query}' with context: '{text[:100]}...'"
